{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS Spam Detection: NLP Text Classification\n",
    "\n",
    "**Author:** Tharun Ponnam  \n",
    "**Email:** tharunponnam007@gmail.com  \n",
    "**Dataset:** UCI SMS Spam Collection\n",
    "\n",
    "This notebook demonstrates a complete text classification pipeline using:\n",
    "- **NLTK** for natural language processing\n",
    "- **Scikit-Learn** for machine learning models\n",
    "- **Pandas** for data manipulation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from src.classifier import WordsClassifier, compare_models\n",
    "from src.data_loader import DataLoader\n",
    "from src.preprocessing import TextPreprocessor\n",
    "from src.feature_extraction import FeatureExtractor\n",
    "from src.model_trainer import ModelTrainer\n",
    "from src.visualization import (\n",
    "    plot_confusion_matrix, plot_roc_curve, plot_class_distribution,\n",
    "    plot_text_length_distribution, plot_wordcloud, plot_model_comparison\n",
    ")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"Environment ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataLoader.load_sms_spam()\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nData Types:\\n{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = DataLoader.get_dataset_stats(df)\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"  Total Samples: {stats['total_samples']:,}\")\n",
    "print(f\"  Classes: {stats['n_classes']}\")\n",
    "print(f\"\\nLabel Distribution:\")\n",
    "for label, count in stats['label_distribution'].items():\n",
    "    label_name = 'Ham' if label == 0 else 'Spam'\n",
    "    pct = count / stats['total_samples'] * 100\n",
    "    print(f\"  {label_name}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nText Length (characters):\")\n",
    "print(f\"  Mean: {stats['text_length']['mean']:.1f}\")\n",
    "print(f\"  Std:  {stats['text_length']['std']:.1f}\")\n",
    "print(f\"  Min:  {stats['text_length']['min']}\")\n",
    "print(f\"  Max:  {stats['text_length']['max']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "plot_class_distribution(\n",
    "    df['label'].values,\n",
    "    class_names=['Ham', 'Spam'],\n",
    "    title='Class Distribution'\n",
    ")\n",
    "plt.subplot(1, 2, 1)\n",
    "colors = ['#3b82f6', '#ef4444']\n",
    "counts = df['label'].value_counts().sort_index()\n",
    "plt.bar(['Ham', 'Spam'], counts.values, color=colors)\n",
    "plt.title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Count')\n",
    "for i, v in enumerate(counts.values):\n",
    "    plt.text(i, v + 50, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df['text_length'] = df['text'].str.len()\n",
    "df[df['label'] == 0]['text_length'].hist(bins=50, alpha=0.6, label='Ham', color='#3b82f6')\n",
    "df[df['label'] == 1]['text_length'].hist(bins=50, alpha=0.6, label='Spam', color='#ef4444')\n",
    "plt.xlabel('Text Length (characters)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Text Length Distribution by Class', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../assets/screenshots/data_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextPreprocessor(\n",
    "    remove_stopwords=True,\n",
    "    use_lemmatization=True\n",
    ")\n",
    "\n",
    "sample_text = \"URGENT! You have WON a $1000 prize. Call NOW at 1-800-555-1234 to claim!!!\"\n",
    "\n",
    "print(\"Original Text:\")\n",
    "print(f\"  {sample_text}\")\n",
    "print(f\"\\nCleaned Text:\")\n",
    "print(f\"  {preprocessor.clean_text(sample_text)}\")\n",
    "print(f\"\\nTokens:\")\n",
    "print(f\"  {preprocessor.tokenize(sample_text)}\")\n",
    "print(f\"\\nProcessed:\")\n",
    "print(f\"  {preprocessor.preprocess(sample_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPOS Tags:\")\n",
    "pos_tags = preprocessor.get_pos_tags(sample_text)\n",
    "for token, tag in pos_tags:\n",
    "    print(f\"  {token:15} -> {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = preprocessor.batch_preprocess(df['text'].tolist(), show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['text', 'processed_text', 'label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = FeatureExtractor(\n",
    "    vectorizer_type='tfidf',\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "features = extractor.fit_transform(df['processed_text'].tolist())\n",
    "\n",
    "print(f\"Feature Matrix Shape: {features.shape}\")\n",
    "print(f\"Vocabulary Size: {extractor.vocabulary_size:,}\")\n",
    "print(f\"Sparsity: {1 - features.nnz / (features.shape[0] * features.shape[1]):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = extractor.get_top_features(features, df['label'].values, n_top=15)\n",
    "\n",
    "print(\"Top Features by Class:\\n\")\n",
    "for label, feats in top_features.items():\n",
    "    label_name = 'Ham' if label == 0 else 'Spam'\n",
    "    print(f\"{label_name}:\")\n",
    "    for feat, score in feats[:10]:\n",
    "        print(f\"  {feat:20} {score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = DataLoader.split_data(df, test_size=0.2, random_state=42)\n",
    "X_train, y_train = splits['train']\n",
    "X_test, y_test = splits['test']\n",
    "\n",
    "print(f\"Training samples: {len(X_train):,}\")\n",
    "print(f\"Test samples: {len(X_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = WordsClassifier(\n",
    "    model_type='naive_bayes',\n",
    "    vectorizer_type='tfidf',\n",
    "    max_features=5000\n",
    ")\n",
    "\n",
    "nb_classifier.fit(X_train.tolist(), y_train.values)\n",
    "\n",
    "nb_metrics = nb_classifier.evaluate(X_test.tolist(), y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = WordsClassifier(\n",
    "    model_type='svm',\n",
    "    vectorizer_type='tfidf',\n",
    "    max_features=5000\n",
    ")\n",
    "\n",
    "svm_classifier.fit(X_train.tolist(), y_train.values)\n",
    "\n",
    "svm_metrics = svm_classifier.evaluate(X_test.tolist(), y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = WordsClassifier(\n",
    "    model_type='random_forest',\n",
    "    vectorizer_type='tfidf',\n",
    "    max_features=5000,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "rf_classifier.fit(X_train.tolist(), y_train.values)\n",
    "\n",
    "rf_metrics = rf_classifier.evaluate(X_test.tolist(), y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compare_models(\n",
    "    df['text'].tolist(),\n",
    "    df['label'].values,\n",
    "    models=['naive_bayes', 'complement_nb', 'svm', 'logistic', 'random_forest'],\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_model_comparison(\n",
    "    results,\n",
    "    title='Model Performance Comparison (5-Fold CV)'\n",
    ")\n",
    "plt.savefig('../assets/screenshots/model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Best Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = results.iloc[0]['model']\n",
    "print(f\"Best Model: {best_model}\")\n",
    "\n",
    "classifier = WordsClassifier(model_type=best_model)\n",
    "classifier.fit(X_train.tolist(), y_train.values)\n",
    "\n",
    "y_pred = classifier.predict(X_test.tolist())\n",
    "y_proba = classifier.predict_proba(X_test.tolist())[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "cm = confusion_matrix(y_test.values, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(y_test.values, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='#2563eb', lw=2, label=f'ROC (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.fill_between(fpr, tpr, alpha=0.2, color='#2563eb')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../assets/screenshots/model_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_texts = df[df['label'] == 0]['processed_text'].tolist()\n",
    "spam_texts = df[df['label'] == 1]['processed_text'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "from wordcloud import WordCloud\n",
    "wc_ham = WordCloud(width=800, height=400, background_color='white',\n",
    "                   colormap='Greens', max_words=100).generate(' '.join(ham_texts[:1000]))\n",
    "plt.imshow(wc_ham, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Ham Messages', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "wc_spam = WordCloud(width=800, height=400, background_color='white',\n",
    "                    colormap='Reds', max_words=100).generate(' '.join(spam_texts))\n",
    "plt.imshow(wc_spam, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Spam Messages', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../assets/screenshots/word_clouds.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Real-time Prediction Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages = [\n",
    "    \"Congratulations! You've won a free vacation. Call now to claim!\",\n",
    "    \"Hey, can we meet for coffee tomorrow at 3pm?\",\n",
    "    \"URGENT: Your bank account has been compromised. Click here immediately.\",\n",
    "    \"Thanks for your help with the project. Really appreciate it!\",\n",
    "    \"FREE ENTRY! Win Â£1000 cash. Text WIN to 80808 now!\"\n",
    "]\n",
    "\n",
    "print(\"Real-time Classification Demo\\n\" + \"=\"*50)\n",
    "\n",
    "for msg in test_messages:\n",
    "    result = classifier.predict_with_confidence([msg])[0]\n",
    "    label = \"SPAM ðŸš¨\" if result['label'] == 1 else \"HAM âœ…\"\n",
    "    conf = result['confidence'] * 100\n",
    "    \n",
    "    print(f\"\\nMessage: {msg[:60]}...\")\n",
    "    print(f\"  â†’ {label} (Confidence: {conf:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('../models/best_classifier.pkl')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_classifier = WordsClassifier.load('../models/best_classifier.pkl')\n",
    "\n",
    "test_msg = \"Free prize waiting for you!\"\n",
    "pred = loaded_classifier.predict([test_msg])[0]\n",
    "print(f\"Test prediction: {'SPAM' if pred == 1 else 'HAM'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This project demonstrates a complete text classification pipeline:\n",
    "\n",
    "1. **Data Loading**: UCI SMS Spam Collection (5,574 messages)\n",
    "2. **Preprocessing**: Tokenization, lemmatization, stopword removal\n",
    "3. **Feature Extraction**: TF-IDF with n-grams\n",
    "4. **Model Training**: Multiple algorithms compared\n",
    "5. **Evaluation**: Cross-validation, confusion matrix, ROC curves\n",
    "\n",
    "**Best Model Performance:**\n",
    "- Accuracy: ~97%\n",
    "- F1-Score: ~96%\n",
    "- ROC-AUC: ~99%\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Tharun Ponnam  \n",
    "**GitHub:** [@tharun-ship-it](https://github.com/tharun-ship-it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
